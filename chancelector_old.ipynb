{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, json, datetime\n",
    "import os, sys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin\n",
    "import uuid\n",
    "from hashlib import md5\n",
    "import dateparser\n",
    "import pandas as pd\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "first_time=False\n",
    "\n",
    "\n",
    "def recombine_link_list(link_list):\n",
    "    rlist = []\n",
    "    t = \"\"\n",
    "    s=-1\n",
    "    for (url, text ,subtitle, desc, user, date ) in link_list:\n",
    "        s = s + 1\n",
    "        try:\n",
    "            rlist.append((s, url, text, subtitle, desc, user, dateparser.parse(date).timestamp()))\n",
    "        except:\n",
    "            print ((s, url, text, subtitle, desc, user, dateparser.parse(date)))\n",
    "            rlist.append((s, url, text, subtitle, desc, user, dateparser.parse(date)))\n",
    "    return rlist\n",
    "\n",
    "def recombine_anno_list(anno_list):\n",
    "    rlist = []\n",
    "    t = \"\"\n",
    "    s=-1\n",
    "    for (a,u,d) in anno_list:\n",
    "        if u==\"\" and d==\"\":\n",
    "            t=t+\" \"+a\n",
    "        else:\n",
    "            s=s+1\n",
    "            t=(t+\" \"+a)\n",
    "            #rlist.append((s,t.replace(\"\\r\\n\", \"\"),u,d))\n",
    "            rlist.append((s,t,u,dateparser.parse(d).timestamp()))\n",
    "            t=\"\"\n",
    "    return rlist\n",
    "\n",
    "def scrape_link_values(link_list_soup_element):\n",
    "    link_url = link_list_soup_element.find('a')['href']\n",
    "    link_attribution_regex = re.compile(r\"\\[(.*),\\s([A-Z][a-z]{2}\\s[\\d]{1,2} [\\d]{4})(?:\\]|,\\slast modified.*?])$\")\n",
    "    try:\n",
    "        link_text = \"\".join(link_list_soup_element.find_next_sibling().find('nobr').strings)\n",
    "    except:\n",
    "        link_text = \"\"\n",
    "    link_subtitle = \"\".join(link_list_soup_element.find('a').strings)\n",
    "  \n",
    "\n",
    "    try:\n",
    "        link_desc = \"\".join(\"\".join(link_list_soup_element.find_next_sibling().find('br').next_element))\n",
    "    except TypeError:\n",
    "        link_desc = \"???\"\n",
    "    link_user = \"\".join(link_list_soup_element.find_next_sibling().find('a').strings)\n",
    "    lstring = \"\".join(link_list_soup_element.find_next_sibling().strings)\n",
    "    \n",
    "    link_attribution_groups = link_attribution_regex.search(\"\".join(link_list_soup_element.find_next_sibling().strings).strip())\n",
    "    #print(link_attribution_groups)\n",
    "    if link_attribution_groups is not None:\n",
    "        #print(link_attribution_groups.group(1)==link_user, \" user link \", link_user)\n",
    "        link_date = link_attribution_groups.group(2)\n",
    "    else:\n",
    "        link_date = \"\".join(link_list_soup_element.find_next_sibling().strings)[lstring.find(link_user)+\n",
    "                len(link_user)+2:lstring.find(']',lstring.find(link_user)+len(link_user))]\n",
    "    try:\n",
    "        link_date = datetime.strptime(\n",
    "            re.search(\"([Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec]{3} \\d{2} \\d{4})\", link_date).group(1), \"%b %d %Y\").isoformat()\n",
    "    except:\n",
    "        pass\n",
    "        #print(link_date)\n",
    "    if link_desc[-1:]==\"[\":\n",
    "        link_desc=link_desc[:-1].strip()\n",
    "    return link_url, link_text, link_subtitle, link_desc, link_user, link_date\n",
    "\n",
    "def scrape_annotations(anno_element):\n",
    "    #print(anno_element)\n",
    "    anno_content = \"\".join(anno_element.find('font', attrs={'class':'fcs'}).strings)\n",
    "    try:\n",
    "        anno_user = \"\".join(anno_element.find('td', attrs={'class':'fcs'}).find('a').strings)\n",
    "        #anno_date = datetime.datetime.now()\n",
    "        anno_date = \"\".join(anno_element.find('td', attrs={'class':'fcs'}).strings)[-11:]\n",
    "    except:\n",
    "        anno_user = \"\"                        \n",
    "        anno_date = \"\"\n",
    "    return anno_content, anno_user, anno_date\n",
    "\n",
    "\n",
    "\n",
    "def get_links(s, url):\n",
    "    r = s.get (url)\n",
    "    page_links_regex = re.compile(\"<a class=\\\"(?:newidea|oldidea)\\\" href=\\\"(/idea/.*?)\\\"\")\n",
    "    link_harvest = [urljoin(url,l).split(\"#\")[0] for l in page_links_regex.findall(r.text)]\n",
    "    return link_harvest\n",
    "\n",
    "def idea_components(hb_link, start_timestamp):\n",
    "    l=hb_link\n",
    "    r = s.get(l)\n",
    "    fetch_time=datetime.datetime.now().timestamp()\n",
    "    update_since = start_timestamp\n",
    "    soup=bs(r.text,\"html\")\n",
    "    mainpanel = soup.find('td', attrs={'class':'mainpanel'})\n",
    "    idea_header = mainpanel.findAll('table')[2]\n",
    "    title = str(\"\".join(idea_header.find('a', attrs={'name':'idea'}).strings))\n",
    "    fetch_id = str(uuid.uuid4())\n",
    "    description = \"\".join(mainpanel.find('font', attrs={'class':'fcl'}).strings)\n",
    "    #votes = self.getvotes(\"\".join(mainpanel.find('td', attrs={'class':'controls'}).find('td', attrs={'valign':'top', 'align':'center'}).strings).replace(\"(\",\"\").replace(\")\",\"\").split(\",\"))\n",
    "    copy = str(\"\".join(idea_header.find('div', attrs={'class':'copy'}).strings))\n",
    "    (user, text_date) = ( n.strip() for n in str(\"\".join(idea_header.find('td', attrs={'class':'fcm'}).strings)).split(\",\"))\n",
    "    #idate = datetime.datetime.strptime(text_date, \"%b %d %Y\").isoformat()\n",
    "    idate=dateparser.parse(text_date).timestamp()\n",
    "    links = recombine_link_list([scrape_link_values(n) for n in idea_header.findAll('font', attrs={'class':'fcm'})])\n",
    "    annos = recombine_anno_list([scrape_annotations(n) for n in idea_header.next_siblings if n.name=='table'])\n",
    "    #print(\"\".join([str(j) for j in [title, description, copy, user, idate, links, annos]]).encode(\"utf-8\"))\n",
    "    ihash = md5(\"\".join([str(j) for j in [title, description, copy, user, idate, links, annos]]).encode(\"utf-8\")).hexdigest()\n",
    "    return {\n",
    "                 \"fetch_id\" : fetch_id,\n",
    "                 \"url\" : l, \n",
    "                 \"hash\" : ihash,\n",
    "                 \"title\":title, \n",
    "                 \"description\" : description, \n",
    "                 \"copy\" : copy, \n",
    "                 \"user\" : user, \n",
    "                 \"idea_date\" : idate, \n",
    "                 \"links\": links, \n",
    "                 \"annos\" : annos,\n",
    "                 \"fetch_date\" : fetch_time,\n",
    "                 \"update_since\" : start_timestamp\n",
    "            }\n",
    "\n",
    "\n",
    "# SQLite requires dates be converted according to some convention - here we'll use integer seconds since epoch\n",
    "# or whatever is convenient.\n",
    "# Also, we have a multi-table structure, since annos and links are collections of records themselves.\n",
    "# So the structure looks like:\n",
    "\n",
    "#   +--------------------+\n",
    "#   |  idea_fetch        |\n",
    "#   +--------------------+\n",
    "#   |  fetch_id (pk)     |\n",
    "#   |  url               |\n",
    "#   |  hash              |\n",
    "#   |  title             |\n",
    "#   |  description       |\n",
    "#   |  copy              |\n",
    "#   |  user              |\n",
    "#   |  idea_date         |\n",
    "#   |  fetch_date        |\n",
    "#   +--------------------+\n",
    "\n",
    "\n",
    "def sql_create_schema(conn,first_time=False):\n",
    "    if first_time:\n",
    "        c = conn.cursor()\n",
    "        c.execute( \"\"\"DROP TABLE idea_fetch\"\"\")\n",
    "        c.close()\n",
    "        c = conn.cursor()\n",
    "        c.execute( \"\"\"CREATE TABLE idea_fetch\n",
    "                    (   fetch_id text,\n",
    "                        url text, \n",
    "                        hash text, \n",
    "                        title text, \n",
    "                        description text, \n",
    "                        copy text, \n",
    "                        user text, \n",
    "                        idea_date real, \n",
    "                        fetch_date real,\n",
    "                        update_since real)\"\"\")\n",
    "        c.close()\n",
    "        c = conn.cursor()\n",
    "        c.execute( \"\"\"DROP TABLE anno_fetch\"\"\")\n",
    "        c.close()\n",
    "        c = conn.cursor()\n",
    "        c.execute( \"\"\"CREATE TABLE anno_fetch\n",
    "                    (   fetch_id text,\n",
    "                        anno_seq integer, \n",
    "                        anno_text text, \n",
    "                        anno_user text, \n",
    "                        anno_date real\n",
    "                        )\"\"\")\n",
    "        c.close()\n",
    "        c = conn.cursor()\n",
    "        c.execute( \"\"\"DROP TABLE link_fetch\"\"\")\n",
    "        c.close()\n",
    "        c = conn.cursor()\n",
    "        c.execute( \"\"\"CREATE TABLE link_fetch\n",
    "                    (   fetch_id text,\n",
    "                        link_seq integer, \n",
    "                        link_url text, \n",
    "                        link_rickroll text, \n",
    "                        link_text text, \n",
    "                        link_anno text,\n",
    "                        link_user text, \n",
    "                        link_date real\n",
    "                        )\"\"\")\n",
    "        c.close()\n",
    "\n",
    "        return True\n",
    "    \n",
    "\n",
    "def store_fetch_record(c,record):\n",
    "    idea_insert_sql = \"\"\"INSERT INTO idea_fetch VALUES\n",
    "                        ( ?, ?, ?, ?, ?, ?, ?, ?, ? )\"\"\"\n",
    "    anno_insert_sql = \"\"\"INSERT INTO anno_fetch VALUES\n",
    "                        ( ?, ?, ?, ?, ? )\"\"\"\n",
    "    link_insert_sql = \"\"\"INSERT INTO link_fetch VALUES\n",
    "                    ( ?, ?, ?, ?, ?, ?, ?, ? )\"\"\"\n",
    "    links_pk = uuid.uuid4()\n",
    "    annos_pk = uuid.uuid4()\n",
    "    idea_values = [record[\"fetch_id\"], \n",
    "                   record[\"url\"], \n",
    "                   record[\"hash\"], \n",
    "                   record[\"title\"], \n",
    "                   record[\"description\"], \n",
    "                   record[\"copy\"], \n",
    "                   record[\"user\"], \n",
    "                   record[\"idea_date\"], \n",
    "                   record[\"fetch_date\"]]\n",
    "    #for e,v in enumerate(idea_values):\n",
    "    #    print(e,v)\n",
    "    c.execute(idea_insert_sql, idea_values)\n",
    "    for anno in record['annos']:\n",
    "        anno_values = [record[\"fetch_id\"], \n",
    "                       anno[0], \n",
    "                       anno[1], \n",
    "                       anno[2], \n",
    "                       anno[3]]\n",
    "        c.execute(anno_insert_sql, anno_values)\n",
    "    \n",
    "    for link in record['links']:\n",
    "        link_values = [record[\"fetch_id\"], \n",
    "                       link[0], \n",
    "                       link[1], \n",
    "                       link[2], \n",
    "                       link[3],\n",
    "                       link[4],\n",
    "                       link[5],\n",
    "                       link[6]]\n",
    "        c.execute(link_insert_sql, link_values)\n",
    "\n",
    "def query_to_recordset(connection, query, parameters=None):\n",
    "    c = connection.cursor()\n",
    "    if parameters is not None:\n",
    "        rs = c.execute(query, parameters)\n",
    "    else:\n",
    "        rs = c.execute(query)\n",
    "    schema = rs.description\n",
    "    return_set = []\n",
    "    for r in rs:\n",
    "        return_set.append({schema[e][0]:r[e] for e in range(0,len(schema))})\n",
    "    rs.close()\n",
    "    c.close()\n",
    "    return return_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print (first_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an idea component is \"novel\" i.e. it has a hash that's not on file, then it can be saved for posterity\n",
    "# It also qualifies for a review for any content that matches the search criteria. \n",
    "# The details of successful searches are then logged independently in such a way that they can be used to \n",
    "# filter out repeat matches. \n",
    "\n",
    "# What should be the logging mechanism? SQLlite probably. Makes sense to create a database to host and persist\n",
    "# the content. \n",
    "conn=None\n",
    "c=None\n",
    "conn = sqlite3.connect('hb_records.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86400\n",
      "https://www.halfbakery.com/view/ftm=r86400:s=Qr:d=irq:dn=100:ds=0:n=Today_27s_20Notions:i=A_20list_20of_20todays_20ideas_20and_20annotations:t=Today_27s_20Notions\n",
      "['https://www.halfbakery.com/idea/Days_20Since_20Hitler_20Was_20Mentioned_20Here', 'https://www.halfbakery.com/idea/_22Unedited_20documentary_22_20movie', 'https://www.halfbakery.com/idea/Autoweeebile_20III', 'https://www.halfbakery.com/idea/10_20Gbps_20ethernet_20using_20USB3', 'https://www.halfbakery.com/idea/epigenetic_20epicureans', 'https://www.halfbakery.com/idea/Autoweeebile_20II', 'https://www.halfbakery.com/idea/Autoweeeebile', 'https://www.halfbakery.com/idea/F_fcrst_20annual_20HalfBakery_20_93Wo_20ist_20der_20F_fchrer_20_3f_94_20programming_20competition_2e', 'https://www.halfbakery.com/idea/light', 'https://www.halfbakery.com/idea/Completely_20Realistic_20Fake_20Candle', 'https://www.halfbakery.com/idea/Plaid_20conductor_20(Redundant_20Array_20of_20Independent_20Conductors)', 'https://www.halfbakery.com/idea/Colouring_20Cook_20Book', 'https://www.halfbakery.com/idea/Merry_20Christmas']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "now = datetime.datetime.now().timestamp()\n",
    "\n",
    "# This makes use of a search url, returning all the ideas posted in some time period (defaulted to a day)\n",
    "a_day = 86400\n",
    "if first_time == True:\n",
    "    days_since_start = (datetime.datetime.now() - datetime.datetime(2020,10,17) ).days\n",
    "    \n",
    "    = now-(a_day * days_since_start)\n",
    "    guess_m = 500\n",
    "else:\n",
    "    start_timestamp = now-(a_day * 1)\n",
    "    guess_m = 100\n",
    "    \n",
    "\n",
    "t_minus = int(now - start_timestamp)\n",
    "\n",
    "print(t_minus)\n",
    "url = \"https://www.halfbakery.com/view/ftm=r{t_minus}:s=Qr:d=irq:dn={m}:ds=0:n=Today_27s_20Notions:i=A_20list_20of_20todays_20ideas_20and_20annotations:t=Today_27s_20Notions\".format(m=guess_m,t_minus=t_minus)\n",
    "#url=\"https://www.halfbakery.com/view/ftm=r5356800:s=Qr:d=irq:do=100:dn=100:ds=0:n=Today_27s_20Notions:i=A_20list_20of_20todays_20ideas_20and_20annotations:t=Today_27s_20Notions\"\n",
    "#url=\"https://www.halfbakery.com/view/ftm=r5356800:s=Qr:d=irq:do=200:dn=100:ds=0:n=Today_27s_20Notions:i=A_20list_20of_20todays_20ideas_20and_20annotations:t=Today_27s_20Notions\"\n",
    "print (url)\n",
    "s = requests.Session()\n",
    "contents = []\n",
    "link_harvest = get_links(s, url)\n",
    "for l in link_harvest:\n",
    "    contents.append(idea_components(l,start_timestamp))\n",
    "lindex = [c['url'] for c in contents]    \n",
    "#conn.row_factory = sqlite3.Row\n",
    "# If this is the first time running, then we need to create the schema\n",
    "if first_time is True:\n",
    "    first_time = False\n",
    "    sql_create_schema(conn, first_time)\n",
    "print (lindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving https://www.halfbakery.com/idea/Days_20Since_20Hitler_20Was_20Mentioned_20Here\n",
      "Saving https://www.halfbakery.com/idea/_22Unedited_20documentary_22_20movie\n",
      "Saving https://www.halfbakery.com/idea/Autoweeebile_20III\n",
      "Saving https://www.halfbakery.com/idea/10_20Gbps_20ethernet_20using_20USB3\n",
      "Saving https://www.halfbakery.com/idea/epigenetic_20epicureans\n",
      "Saving https://www.halfbakery.com/idea/Autoweeebile_20II\n",
      "Saving https://www.halfbakery.com/idea/Autoweeeebile\n",
      "Saving https://www.halfbakery.com/idea/F_fcrst_20annual_20HalfBakery_20_93Wo_20ist_20der_20F_fchrer_20_3f_94_20programming_20competition_2e\n",
      "Saving https://www.halfbakery.com/idea/light\n",
      "Saving https://www.halfbakery.com/idea/Completely_20Realistic_20Fake_20Candle\n",
      "Saving https://www.halfbakery.com/idea/Plaid_20conductor_20(Redundant_20Array_20of_20Independent_20Conductors)\n",
      "Saving https://www.halfbakery.com/idea/Colouring_20Cook_20Book\n",
      "Saving https://www.halfbakery.com/idea/Merry_20Christmas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = conn.cursor()\n",
    "retrieve_latest_sql = \"\"\"\n",
    "                select i.url, i.hash, i.fetch_date \n",
    "                from (\n",
    "                    select url, max(fetch_date) max_fetch_date\n",
    "                    from (\n",
    "                        select url, fetch_date\n",
    "                         from idea_fetch\n",
    "                         where url in ({in_list}))\n",
    "                    group by url) as latest_v\n",
    "                    join idea_fetch i on \n",
    "                    i.url = latest_v.url and\n",
    "                    i.fetch_date = latest_v.max_fetch_date \n",
    "                \"\"\".format(in_list = \",\".join([\"?\" for l in lindex]))\n",
    "\n",
    "rs = c.execute(retrieve_latest_sql, lindex)\n",
    "r_cols = rs.description\n",
    "content_filter=[]\n",
    "for r in rs:\n",
    "    lindex_i = lindex.index(r[0])\n",
    "    if contents[lindex_i]['hash']==r[1]:\n",
    "        print (\"Hashmatch - no update\")\n",
    "        content_filter.append(r[0])\n",
    "    else:\n",
    "        print (\"Hashfail - got update\")\n",
    "        \n",
    "rs.close()\n",
    "c.close()\n",
    "\n",
    "save_list = list(set(lindex).difference(set(content_filter)))\n",
    "\n",
    "for c in contents:\n",
    "    if c['url'] in save_list:\n",
    "        store_fetch_record(conn, c)\n",
    "        print(\"Saving\", c['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.halfbakery.com/idea/10_20Gbps_20ethernet_20using_20USB3', 'ed0a2923ee878316b815de9d64c4a00e', 1608387461.935288]\n",
      "['https://www.halfbakery.com/idea/Autoweeebile_20II', '52c82fb90379f101fa5f45d02e9aa4b8', 1608387462.517439]\n",
      "['https://www.halfbakery.com/idea/Autoweeebile_20III', '56b0215524e63cb6ac6deb2569297edb', 1608387460.537451]\n",
      "['https://www.halfbakery.com/idea/Autoweeeebile', '10c45666c06d3544ad71e2941f471c0d', 1608387464.127641]\n",
      "['https://www.halfbakery.com/idea/Colouring_20Cook_20Book', '6b7459c44af937e23baebcde12646028', 1608387466.490251]\n",
      "['https://www.halfbakery.com/idea/Completely_20Realistic_20Fake_20Candle', '0a1f0238e4a057e9fb692df487aeaf9d', 1608387465.667251]\n",
      "['https://www.halfbakery.com/idea/Days_20Since_20Hitler_20Was_20Mentioned_20Here', '92f181d2e35d41f2df4d8e9f9de6450f', 1608387459.401444]\n",
      "['https://www.halfbakery.com/idea/F_fcrst_20annual_20HalfBakery_20_93Wo_20ist_20der_20F_fchrer_20_3f_94_20programming_20competition_2e', 'd6374822148bf75fecb9ff09f5c42875', 1608387464.797524]\n",
      "['https://www.halfbakery.com/idea/Merry_20Christmas', 'c00ad0818961be51dfc05c5344e3ada8', 1608387468.474592]\n",
      "['https://www.halfbakery.com/idea/Plaid_20conductor_20(Redundant_20Array_20of_20Independent_20Conductors)', '0ce9aad08597ccaaa231c9c92cc4b987', 1608387466.16834]\n",
      "['https://www.halfbakery.com/idea/_22Unedited_20documentary_22_20movie', '57d70008d6cf831e27efd5ff7c902610', 1608387460.268808]\n",
      "['https://www.halfbakery.com/idea/epigenetic_20epicureans', 'efd2ac8a2e5a629cae7faf3cf0831ede', 1608387462.237903]\n",
      "['https://www.halfbakery.com/idea/light', 'b94e4bcf88fd2164e5f4fa6e6b33b85c', 1608387465.32974]\n"
     ]
    }
   ],
   "source": [
    "c = conn.cursor()\n",
    "rs = c.execute(\"\"\"select url, hash, fetch_date\n",
    "                from idea_fetch \n",
    "                order by url, fetch_date \"\"\")\n",
    "r_cols = rs.description\n",
    "\n",
    "for r in rs:\n",
    "    #print ( [(r_cols[e][0], r[e]) for e,v in enumerate(r)] )\n",
    "    print ( [(r[e]) for e,v in enumerate(r)] )\n",
    "rs.close()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1608378829.873383\n"
     ]
    }
   ],
   "source": [
    "# Pick a search date and retrieve all the latest versions of chached content collected since that date. \n",
    "search_date = datetime.datetime.now().timestamp()-(86400*0.1)\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "# This does a string replace, rather than a strict parameter-style query, because\n",
    "# I can't get the wretched parameterised one to work without reporting an unmatched datatype\n",
    "# error. Suspect it's due to an error in the schema. \n",
    "retrieve_latest_sql = \"\"\"\n",
    "                select i.url, i.hash, i.fetch_date \n",
    "                from (\n",
    "                    select url, max(fetch_date) max_fetch_date\n",
    "                    from (\n",
    "                        select url, fetch_date\n",
    "                         from idea_fetch\n",
    "                         where fetch_date > {search_date})\n",
    "                    group by url) as latest_v\n",
    "                    join idea_fetch i on \n",
    "                    i.url = latest_v.url and\n",
    "                    i.fetch_date = latest_v.max_fetch_date \n",
    "                    order by i.fetch_date\n",
    "                \"\"\".format(search_date=search_date)\n",
    "\n",
    "print(search_date)\n",
    "\n",
    "# The query returns the collection of ideas that's been most recently fetched in the last time period. \n",
    "# If they've been fetched, then they would have been up on the \"recent\" search list, but it's not necessarily\n",
    "# the case that they were edited at this time\n",
    "# The timestamp used as an effective search criterea could be inferred from the search query - and used to\n",
    "# define bounds on the time between which the update happened. \n",
    "idea_set = query_to_recordset(conn, retrieve_latest_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.halfbakery.com/idea/Days_20Since_20Hitler_20Was_20Mentioned_20Here',\n",
       "  'hash': '92f181d2e35d41f2df4d8e9f9de6450f',\n",
       "  'fetch_date': 1608387459.401444},\n",
       " {'url': 'https://www.halfbakery.com/idea/_22Unedited_20documentary_22_20movie',\n",
       "  'hash': '57d70008d6cf831e27efd5ff7c902610',\n",
       "  'fetch_date': 1608387460.268808},\n",
       " {'url': 'https://www.halfbakery.com/idea/Autoweeebile_20III',\n",
       "  'hash': '56b0215524e63cb6ac6deb2569297edb',\n",
       "  'fetch_date': 1608387460.537451},\n",
       " {'url': 'https://www.halfbakery.com/idea/10_20Gbps_20ethernet_20using_20USB3',\n",
       "  'hash': 'ed0a2923ee878316b815de9d64c4a00e',\n",
       "  'fetch_date': 1608387461.935288},\n",
       " {'url': 'https://www.halfbakery.com/idea/epigenetic_20epicureans',\n",
       "  'hash': 'efd2ac8a2e5a629cae7faf3cf0831ede',\n",
       "  'fetch_date': 1608387462.237903},\n",
       " {'url': 'https://www.halfbakery.com/idea/Autoweeebile_20II',\n",
       "  'hash': '52c82fb90379f101fa5f45d02e9aa4b8',\n",
       "  'fetch_date': 1608387462.517439},\n",
       " {'url': 'https://www.halfbakery.com/idea/Autoweeeebile',\n",
       "  'hash': '10c45666c06d3544ad71e2941f471c0d',\n",
       "  'fetch_date': 1608387464.127641},\n",
       " {'url': 'https://www.halfbakery.com/idea/F_fcrst_20annual_20HalfBakery_20_93Wo_20ist_20der_20F_fchrer_20_3f_94_20programming_20competition_2e',\n",
       "  'hash': 'd6374822148bf75fecb9ff09f5c42875',\n",
       "  'fetch_date': 1608387464.797524},\n",
       " {'url': 'https://www.halfbakery.com/idea/light',\n",
       "  'hash': 'b94e4bcf88fd2164e5f4fa6e6b33b85c',\n",
       "  'fetch_date': 1608387465.32974},\n",
       " {'url': 'https://www.halfbakery.com/idea/Completely_20Realistic_20Fake_20Candle',\n",
       "  'hash': '0a1f0238e4a057e9fb692df487aeaf9d',\n",
       "  'fetch_date': 1608387465.667251},\n",
       " {'url': 'https://www.halfbakery.com/idea/Plaid_20conductor_20(Redundant_20Array_20of_20Independent_20Conductors)',\n",
       "  'hash': '0ce9aad08597ccaaa231c9c92cc4b987',\n",
       "  'fetch_date': 1608387466.16834},\n",
       " {'url': 'https://www.halfbakery.com/idea/Colouring_20Cook_20Book',\n",
       "  'hash': '6b7459c44af937e23baebcde12646028',\n",
       "  'fetch_date': 1608387466.490251},\n",
       " {'url': 'https://www.halfbakery.com/idea/Merry_20Christmas',\n",
       "  'hash': 'c00ad0818961be51dfc05c5344e3ada8',\n",
       "  'fetch_date': 1608387468.474592}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idea_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idea_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for bad link dates\n",
    "sql=\"\"\"select i.fetch_id, url, hash, link_text, link_anno, link_user, link_date from \n",
    "        link_fetch l\n",
    "        left join idea_fetch i on i.fetch_id=l.fetch_id\n",
    "        where link_date is null\n",
    "        \"\"\"\n",
    "ds = query_to_recordset(conn, sql)\n",
    "pd.DataFrame(ds)#['url'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(*)\n",
       "0        13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for bad link dates\n",
    "sql=\"\"\"select count(*) from idea_fetch\n",
    "        \"\"\"\n",
    "ds = query_to_recordset(conn, sql)\n",
    "pd.DataFrame(ds)#['url'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea_components(\"https://www.halfbakery.com/idea/Film_20Noir_20Home\", 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a view of attributable contributions - ideas, links and annotations - \n",
    "# flattened into a single table containing \n",
    "# url, fetch_id, date, user, contribution_type and text\n",
    "\n",
    "get_ideas_sql=\"\"\"\n",
    "                select url, i.fetch_id, idea_date date, user, \"idea\" ctype, copy text  \n",
    "                from \n",
    "                idea_fetch i\n",
    "                join  (select i.fetch_id from \n",
    "                        (select fetch_id, url, max(fetch_date) max_fetch_date\n",
    "                        from (\n",
    "                        select fetch_id, url, fetch_date\n",
    "                        from idea_fetch\n",
    "                        where fetch_date > {search_date})\n",
    "                        group by fetch_id, url) as latest_v\n",
    "                        join idea_fetch i on \n",
    "                        i.url = latest_v.url and\n",
    "                        i.fetch_date = latest_v.max_fetch_date \n",
    "                        order by i.fetch_date) as latest\n",
    "                        on i.fetch_id = latest.fetch_id\n",
    "                    \n",
    "\"\"\".format(search_date=search_date)\n",
    "\n",
    "ds = query_to_recordset(conn, get_ideas_sql)\n",
    "ideas_df=pd.DataFrame(ds)#['url'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a view of attributable contributions - ideas, links and annotations - \n",
    "# flattened into a single table containing \n",
    "# url, fetch_id, date, user, contribution_type and text\n",
    "\n",
    "get_annos_sql=\"\"\"\n",
    "                \n",
    "                \n",
    "                select i.url, a.fetch_id, anno_date date, anno_user user, \"anno\" ctype, anno_text text  \n",
    "                from \n",
    "                anno_fetch a\n",
    "                join idea_fetch i on a.fetch_id = i.fetch_id\n",
    "                join  (select i.fetch_id from \n",
    "                        (select fetch_id, url, max(fetch_date) max_fetch_date\n",
    "                        from (\n",
    "                        select fetch_id, url, fetch_date\n",
    "                        from idea_fetch\n",
    "                        where fetch_date > {search_date})\n",
    "                        group by fetch_id, url) as latest_v\n",
    "                        join idea_fetch i on \n",
    "                        i.url = latest_v.url and\n",
    "                        i.fetch_date = latest_v.max_fetch_date \n",
    "                        order by i.fetch_date) as latest\n",
    "                        on i.fetch_id = latest.fetch_id\n",
    "                    \n",
    "\"\"\".format(search_date=search_date)\n",
    "\n",
    "ds = query_to_recordset(conn, get_annos_sql)\n",
    "annos_df=pd.DataFrame(ds)#['url'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a view of attributable contributions - ideas, links and annotations - \n",
    "# flattened into a single table containing \n",
    "# url, fetch_id, date, user, contribution_type and text\n",
    "\n",
    "get_links_sql=\"\"\"\n",
    "                \n",
    "                \n",
    "                select i.url, l.fetch_id, link_date date, link_user user, \"link\" ctype, link_text || \" \" || link_anno text  \n",
    "                from \n",
    "                link_fetch l\n",
    "                join idea_fetch i on l.fetch_id = i.fetch_id\n",
    "                join  (select i.fetch_id from \n",
    "                        (select fetch_id, url, max(fetch_date) max_fetch_date\n",
    "                        from (\n",
    "                        select fetch_id, url, fetch_date\n",
    "                        from idea_fetch\n",
    "                        where fetch_date > {search_date})\n",
    "                        group by fetch_id, url) as latest_v\n",
    "                        join idea_fetch i on \n",
    "                        i.url = latest_v.url and\n",
    "                        i.fetch_date = latest_v.max_fetch_date \n",
    "                        order by i.fetch_date) as latest\n",
    "                        on i.fetch_id = latest.fetch_id\n",
    "                    \n",
    "\"\"\".format(search_date=search_date)\n",
    "\n",
    "ds = query_to_recordset(conn, get_links_sql)\n",
    "links_df= pd.DataFrame(ds)#['url'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_df = pd.concat([ideas_df, annos_df, links_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_d = {\"Hitler\" : [re.compile(r\"(?i)\\b(hitler)\\b\")]}\n",
    "def multi_matcher(text, match_d):\n",
    "    matches={}\n",
    "    wbs=[]\n",
    "    wb_regex=re.compile(r\"(\\b)\")\n",
    "    for m in wb_regex.finditer(text):\n",
    "        if m is not None:\n",
    "            wbs.append(m.span()[0])\n",
    "    for k,v in match_d.items():\n",
    "        matches[k]=[]\n",
    "        for vv in v:\n",
    "            m = vv.finditer(text)\n",
    "            if m is not None:\n",
    "                for mg in m:\n",
    "                    sp=mg.span()\n",
    "                    try:\n",
    "                        start_pos = [w for w in wbs if w < sp[0]-10][-1]\n",
    "                    except IndexError:\n",
    "                        start_pos = 0   \n",
    "                    try:\n",
    "                        end_pos = [w for w in wbs if w > sp[1]+10][0]\n",
    "                    except IndexError:\n",
    "                        end_pos = len(text)\n",
    "                    matches[k].append ((sp, \"//\" + text[start_pos:end_pos] + \"//\"))\n",
    "    for k in matches.keys():\n",
    "        if matches[k]==[]:\n",
    "            matches[k]=None\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttext = \"Hitler had a little dog, it's teeth caused dresses to fit her. And everywhere that Hitler went, she called it Adolph Hitler.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hitler': [((0, 6), '//Hitler had a little//'),\n",
       "  ((83, 89), '//everywhere that Hitler went, she //'),\n",
       "  ((117, 123), '// it Adolph Hitler.//')]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_matcher(ttext, match_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmatch = contribution_df['text'].apply(lambda x : multi_matcher(x, match_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_df[\"matches\"] = hmatch[hmatch.apply(lambda x : len(x)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>fetch_id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>ctype</th>\n",
       "      <th>text</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602370800</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>idea</td>\n",
       "      <td>Hitler seems to pop up a lot here. There's the...</td>\n",
       "      <td>{'Hitler': [((0, 6), '//Hitler seems to pop//'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602370800</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>October 10  -Hitler was a vegetarian, you kno...</td>\n",
       "      <td>{'Hitler': [((14, 20), '//October 10  -Hitler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602370800</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>Oct 11 -Hitler proposed something similar for...</td>\n",
       "      <td>{'Hitler': [((9, 15), '// Oct 11 -Hitler propo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>4and20</td>\n",
       "      <td>anno</td>\n",
       "      <td>You know those TV quizzes, 'Did Hitler or Tru...</td>\n",
       "      <td>{'Hitler': [((33, 39), '//quizzes, 'Did Hitler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>We want 8th Hitler of 7 or we're not playing ...</td>\n",
       "      <td>{'Hitler': [((13, 19), '//We want 8th Hitler o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>Or minutes. Maybe seconds. Anyway, here it is...</td>\n",
       "      <td>{'Hitler': [((84, 90), '//Days Since Hitler Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>xenzag</td>\n",
       "      <td>anno</td>\n",
       "      <td>I think Hitler warrants his own Halfbakery ca...</td>\n",
       "      <td>{'Hitler': [((9, 15), '// I think Hitler warra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>Isn't there a paradox inherent in this idea, ...</td>\n",
       "      <td>{'Hitler': [((103, 109), '//automatically ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>xenzag</td>\n",
       "      <td>anno</td>\n",
       "      <td>Ha - Gump is the new \"Godwin character\" for m...</td>\n",
       "      <td>{'Hitler': [((93, 99), '// forgotten Hitler.//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602457200</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>And just like that, with a few clicks of the ...</td>\n",
       "      <td>{'Hitler': [((89, 95), '//Chenjerai \"Hitler\" H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602630000</td>\n",
       "      <td>spidermother</td>\n",
       "      <td>anno</td>\n",
       "      <td>Ah, but you see, that was an anti-Hitler, whi...</td>\n",
       "      <td>{'Hitler': [((35, 41), '//was an anti-Hitler, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602630000</td>\n",
       "      <td>xenzag</td>\n",
       "      <td>anno</td>\n",
       "      <td>I was going to post an idea for a Hitler Boot...</td>\n",
       "      <td>{'Hitler': [((35, 41), '//idea for a Hitler Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602630000</td>\n",
       "      <td>spidermother</td>\n",
       "      <td>anno</td>\n",
       "      <td>I'll be waving to you from the Chaplin boot c...</td>\n",
       "      <td>{'Hitler': [((60, 66), '//. (An anti-Hitler co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602630000</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>I'm looking forward to posting the first \"(1)...</td>\n",
       "      <td>{'Hitler': [((61, 67), '// \r\n",
       "since \r\n",
       "Hitler wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602630000</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>\"Hitler negative space\" (0) days without Hitl...</td>\n",
       "      <td>{'Hitler': [((2, 8), '// \"Hitler negative spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602802800</td>\n",
       "      <td>xenzag</td>\n",
       "      <td>link</td>\n",
       "      <td>Hitler Nutcracker</td>\n",
       "      <td>{'Hitler': [((0, 6), '//Hitler Nutcracker//')]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602802800</td>\n",
       "      <td>2 fries shy of a happy meal</td>\n",
       "      <td>anno</td>\n",
       "      <td>Y'know... I don't think I've ever once mentio...</td>\n",
       "      <td>{'Hitler': [((50, 56), '// mentioned Hitler he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602802800</td>\n",
       "      <td>xenzag</td>\n",
       "      <td>anno</td>\n",
       "      <td>Some research reveals many \"Hitler products\" ...</td>\n",
       "      <td>{'Hitler': [((29, 35), '//reveals many \"Hitler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1602889200</td>\n",
       "      <td>xenzag</td>\n",
       "      <td>anno</td>\n",
       "      <td>Hitler/Gump comparisons are a bit pass√© after...</td>\n",
       "      <td>{'Hitler': [((1, 7), '// Hitler/Gump compariso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1603148400</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>//The second question is this: Is there a \"Hi...</td>\n",
       "      <td>{'Hitler': [((44, 50), '//Is there a \"Hitler v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1603756800</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>Hitler was last metioned by     user:[xenzag]...</td>\n",
       "      <td>{'Hitler': [((1, 7), '// Hitler was last metio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1603843200</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>Hitler was last mentioned by user:[xenzag]in ...</td>\n",
       "      <td>{'Hitler': [((1, 7), '// Hitler was last menti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1604275200</td>\n",
       "      <td>doctorremulac3</td>\n",
       "      <td>anno</td>\n",
       "      <td>What's the Seinfeld/Hitler thing spidermother...</td>\n",
       "      <td>{'Hitler': [((21, 27), '//the Seinfeld/Hitler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1607904000</td>\n",
       "      <td>pocmloc</td>\n",
       "      <td>anno</td>\n",
       "      <td>What happens if you mention Hitler in this idea?</td>\n",
       "      <td>{'Hitler': [((29, 35), '//you mention Hitler i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1607904000</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>It's automatically excluded by the algorithm*...</td>\n",
       "      <td>{'Hitler': [((86, 92), '//instantiations of Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>https://www.halfbakery.com/idea/F_fcrst_20annu...</td>\n",
       "      <td>e98ddf01-e174-4203-bdc0-ee1e9507986e</td>\n",
       "      <td>1607990400</td>\n",
       "      <td>pocmloc</td>\n",
       "      <td>anno</td>\n",
       "      <td>I think there should be a Hitler category</td>\n",
       "      <td>{'Hitler': [((27, 33), '//should be a Hitler c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1607990400</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>Up to you. But it definitely needs cleaning u...</td>\n",
       "      <td>{'Hitler': [((120, 126), '//here for a Hitler-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.halfbakery.com/idea/F_fcrst_20annu...</td>\n",
       "      <td>e98ddf01-e174-4203-bdc0-ee1e9507986e</td>\n",
       "      <td>1607990400</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>link</td>\n",
       "      <td>Days Since Hitler Was Mentioned Here The genes...</td>\n",
       "      <td>{'Hitler': [((11, 17), '//Days Since Hitler Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://www.halfbakery.com/idea/Days_20Since_2...</td>\n",
       "      <td>bb1cfafa-9386-43c6-820f-3a3716d3b25e</td>\n",
       "      <td>1608076800</td>\n",
       "      <td>8th of 7</td>\n",
       "      <td>anno</td>\n",
       "      <td>Der F√ºhrer was last mentioned by user:[pocmlo...</td>\n",
       "      <td>{'Hitler': [((59, 65), '//in thread \"Hitler\"\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "86   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "85   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "120  https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "105  https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "89   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "59   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "72   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "45   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "25   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "23   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "60   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "64   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "68   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "0    https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "4    https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "113  https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "91   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "53   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "15   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "52   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "51   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "109  https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "108  https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "75   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "184  https://www.halfbakery.com/idea/F_fcrst_20annu...   \n",
       "101  https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "16   https://www.halfbakery.com/idea/F_fcrst_20annu...   \n",
       "35   https://www.halfbakery.com/idea/Days_20Since_2...   \n",
       "\n",
       "                                 fetch_id        date  \\\n",
       "0    bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602370800   \n",
       "86   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602370800   \n",
       "85   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602370800   \n",
       "120  bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "105  bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "89   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "59   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "72   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "45   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "25   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602457200   \n",
       "23   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602630000   \n",
       "60   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602630000   \n",
       "64   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602630000   \n",
       "68   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602630000   \n",
       "0    bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602630000   \n",
       "4    bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602802800   \n",
       "113  bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602802800   \n",
       "91   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602802800   \n",
       "53   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1602889200   \n",
       "15   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1603148400   \n",
       "52   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1603756800   \n",
       "51   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1603843200   \n",
       "109  bb1cfafa-9386-43c6-820f-3a3716d3b25e  1604275200   \n",
       "108  bb1cfafa-9386-43c6-820f-3a3716d3b25e  1607904000   \n",
       "75   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1607904000   \n",
       "184  e98ddf01-e174-4203-bdc0-ee1e9507986e  1607990400   \n",
       "101  bb1cfafa-9386-43c6-820f-3a3716d3b25e  1607990400   \n",
       "16   e98ddf01-e174-4203-bdc0-ee1e9507986e  1607990400   \n",
       "35   bb1cfafa-9386-43c6-820f-3a3716d3b25e  1608076800   \n",
       "\n",
       "                            user ctype  \\\n",
       "0                 doctorremulac3  idea   \n",
       "86                doctorremulac3  anno   \n",
       "85                doctorremulac3  anno   \n",
       "120                       4and20  anno   \n",
       "105                     8th of 7  anno   \n",
       "89                doctorremulac3  anno   \n",
       "59                        xenzag  anno   \n",
       "72                      8th of 7  anno   \n",
       "45                        xenzag  anno   \n",
       "25                doctorremulac3  anno   \n",
       "23                  spidermother  anno   \n",
       "60                        xenzag  anno   \n",
       "64                  spidermother  anno   \n",
       "68                doctorremulac3  anno   \n",
       "0                       8th of 7  anno   \n",
       "4                         xenzag  link   \n",
       "113  2 fries shy of a happy meal  anno   \n",
       "91                        xenzag  anno   \n",
       "53                        xenzag  anno   \n",
       "15                doctorremulac3  anno   \n",
       "52                      8th of 7  anno   \n",
       "51                      8th of 7  anno   \n",
       "109               doctorremulac3  anno   \n",
       "108                      pocmloc  anno   \n",
       "75                      8th of 7  anno   \n",
       "184                      pocmloc  anno   \n",
       "101                     8th of 7  anno   \n",
       "16                      8th of 7  link   \n",
       "35                      8th of 7  anno   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Hitler seems to pop up a lot here. There's the...   \n",
       "86    October 10  -Hitler was a vegetarian, you kno...   \n",
       "85    Oct 11 -Hitler proposed something similar for...   \n",
       "120   You know those TV quizzes, 'Did Hitler or Tru...   \n",
       "105   We want 8th Hitler of 7 or we're not playing ...   \n",
       "89    Or minutes. Maybe seconds. Anyway, here it is...   \n",
       "59    I think Hitler warrants his own Halfbakery ca...   \n",
       "72    Isn't there a paradox inherent in this idea, ...   \n",
       "45    Ha - Gump is the new \"Godwin character\" for m...   \n",
       "25    And just like that, with a few clicks of the ...   \n",
       "23    Ah, but you see, that was an anti-Hitler, whi...   \n",
       "60    I was going to post an idea for a Hitler Boot...   \n",
       "64    I'll be waving to you from the Chaplin boot c...   \n",
       "68    I'm looking forward to posting the first \"(1)...   \n",
       "0     \"Hitler negative space\" (0) days without Hitl...   \n",
       "4                                   Hitler Nutcracker    \n",
       "113   Y'know... I don't think I've ever once mentio...   \n",
       "91    Some research reveals many \"Hitler products\" ...   \n",
       "53    Hitler/Gump comparisons are a bit pass√© after...   \n",
       "15    //The second question is this: Is there a \"Hi...   \n",
       "52    Hitler was last metioned by     user:[xenzag]...   \n",
       "51    Hitler was last mentioned by user:[xenzag]in ...   \n",
       "109   What's the Seinfeld/Hitler thing spidermother...   \n",
       "108   What happens if you mention Hitler in this idea?   \n",
       "75    It's automatically excluded by the algorithm*...   \n",
       "184          I think there should be a Hitler category   \n",
       "101   Up to you. But it definitely needs cleaning u...   \n",
       "16   Days Since Hitler Was Mentioned Here The genes...   \n",
       "35    Der F√ºhrer was last mentioned by user:[pocmlo...   \n",
       "\n",
       "                                               matches  \n",
       "0    {'Hitler': [((0, 6), '//Hitler seems to pop//'...  \n",
       "86   {'Hitler': [((14, 20), '//October 10  -Hitler ...  \n",
       "85   {'Hitler': [((9, 15), '// Oct 11 -Hitler propo...  \n",
       "120  {'Hitler': [((33, 39), '//quizzes, 'Did Hitler...  \n",
       "105  {'Hitler': [((13, 19), '//We want 8th Hitler o...  \n",
       "89   {'Hitler': [((84, 90), '//Days Since Hitler Wa...  \n",
       "59   {'Hitler': [((9, 15), '// I think Hitler warra...  \n",
       "72   {'Hitler': [((103, 109), '//automatically ment...  \n",
       "45   {'Hitler': [((93, 99), '// forgotten Hitler.//...  \n",
       "25   {'Hitler': [((89, 95), '//Chenjerai \"Hitler\" H...  \n",
       "23   {'Hitler': [((35, 41), '//was an anti-Hitler, ...  \n",
       "60   {'Hitler': [((35, 41), '//idea for a Hitler Bo...  \n",
       "64   {'Hitler': [((60, 66), '//. (An anti-Hitler co...  \n",
       "68   {'Hitler': [((61, 67), '// \n",
       "since \n",
       "Hitler wa...  \n",
       "0    {'Hitler': [((2, 8), '// \"Hitler negative spac...  \n",
       "4      {'Hitler': [((0, 6), '//Hitler Nutcracker//')]}  \n",
       "113  {'Hitler': [((50, 56), '// mentioned Hitler he...  \n",
       "91   {'Hitler': [((29, 35), '//reveals many \"Hitler...  \n",
       "53   {'Hitler': [((1, 7), '// Hitler/Gump compariso...  \n",
       "15   {'Hitler': [((44, 50), '//Is there a \"Hitler v...  \n",
       "52   {'Hitler': [((1, 7), '// Hitler was last metio...  \n",
       "51   {'Hitler': [((1, 7), '// Hitler was last menti...  \n",
       "109  {'Hitler': [((21, 27), '//the Seinfeld/Hitler ...  \n",
       "108  {'Hitler': [((29, 35), '//you mention Hitler i...  \n",
       "75   {'Hitler': [((86, 92), '//instantiations of Hi...  \n",
       "184  {'Hitler': [((27, 33), '//should be a Hitler c...  \n",
       "101  {'Hitler': [((120, 126), '//here for a Hitler-...  \n",
       "16   {'Hitler': [((11, 17), '//Days Since Hitler Wa...  \n",
       "35   {'Hitler': [((59, 65), '//in thread \"Hitler\"\\n...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_df[contribution_df[\"matches\"].apply(lambda x : x[\"Hitler\"] is not None)].sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
